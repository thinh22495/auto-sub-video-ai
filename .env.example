# =============================================================================
# AutoSubAI Configuration
# Copy this file to .env and modify as needed
# =============================================================================

# Server
AUTOSUB_PORT=8080
AUTOSUB_DEBUG=false

# Paths (inside Docker container - change only if you modify volume mounts)
AUTOSUB_VIDEO_INPUT_DIR=/data/videos
AUTOSUB_SUBTITLE_OUTPUT_DIR=/data/subtitles
AUTOSUB_VIDEO_OUTPUT_DIR=/data/output
AUTOSUB_MODEL_DIR=/data/models
AUTOSUB_DB_PATH=/data/db/autosub.db

# AI Models
AUTOSUB_DEFAULT_WHISPER_MODEL=large-v3-turbo
AUTOSUB_DEFAULT_OLLAMA_MODEL=qwen2.5:7b
AUTOSUB_OLLAMA_BASE_URL=http://autosub-ollama:11434
AUTOSUB_WHISPER_DEVICE=auto
AUTOSUB_WHISPER_COMPUTE_TYPE=auto

# Processing
AUTOSUB_MAX_CONCURRENT_JOBS=2
AUTOSUB_GPU_WORKER_CONCURRENCY=1
AUTOSUB_CPU_WORKER_CONCURRENCY=4
AUTOSUB_MAX_UPLOAD_SIZE_MB=10000

# Redis
AUTOSUB_REDIS_URL=redis://autosub-redis:6379/0

# Subtitle Defaults
AUTOSUB_DEFAULT_SUBTITLE_FORMAT=srt
AUTOSUB_DEFAULT_MAX_LINE_LENGTH=42
AUTOSUB_DEFAULT_MAX_LINES=2

# Cleanup
AUTOSUB_TEMP_FILE_MAX_AGE_HOURS=24
AUTOSUB_COMPLETED_JOB_RETENTION_DAYS=30
